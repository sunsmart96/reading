# 人工智能简史

# 1.达特茅斯会议:人工智能的缘起

人工智能的起源，公认是起源于达特茅斯会议。因为在这场会议上正式提出了人工智能的概念。



克门尼---达特茅斯学院数学系主任，把麦卡锡招聘进来，发明BASIC语言。他是当时达特茅斯学院数学系的主任，是他把明斯基及麦肯锡招聘到达特茅斯学院任教。



会议的参与者：

塞弗里奇---主张神经网络，人工智能先驱，机器感知之父，模式识别创始人，写了第一个可工作的AI程序

纽维尔---主张模拟心智，人工智能下棋，图灵奖获得者

麦卡锡---会议召集者，发明LISP语言，图灵奖获得者，提出人工智能概念

明斯基---MIT人工智能实验室创始人，图灵奖获得者

香农---信息论创始人，现代通信之父

司马贺---图灵奖得主，诺贝尔经济学奖得主

罗切斯特---编写第一个汇编语言，IBM701计算机总设计师

塞缪尔---研究跳棋，首个棋类AI程序开发者，跟高德纳一起开发Tex

伯恩斯坦---研究象棋

摩尔---达特茅斯学院教授，后去IBM

所罗门诺夫---提出算法概率论，



会议上纽维尔和司马贺公布了一款程序“逻辑理论家”，可以证明罗素的《数学原理》中很大一部分定理。



会议制定研究方向：自动计算机(可编程计算机)、编程语言、神经网络、计算规模理论(计算复杂性)、自我改进(机器学习)、抽象、随机性与创见性。这七个方向可以说主导了未来半个多世纪计算机科学与相关工程技术的发展。可见其前瞻性。



人工智能在正式提出后十年，1965年照样被攻击“炼丹”。这与深度神经网络崛起后的评价类似。



**我认为：数学、哲学、人工智能不是独立的。想推动人工智能发生革命性发展，一定要创建新的数学工具，并在哲学上开创新的思想。每一个AI技术流派背后都有深刻的哲学数学的影子。这些思想是指导设计新的AI算法的基础。**



# 2.自动定理证明兴衰纪

人工智能符号派的思想源头和理论基础就是定理证明。第一个开发出定理证明程序的人是逻辑学家戴维斯，他开发的程序可以证明。后续就是在达特茅斯会议上提出的“逻辑理论家”的定理证明器程序。可以解决《数学原理》中的很大一部分问题。王浩使用IBM701机编写的程序可以解决《数学原理》中全部150条一阶逻辑定理和200条命题逻辑定理。王浩在进一步研究机器证明数学定理的复杂形式问题，就要分析问题和算法的可计算性和复杂性。他的学生库克发表《定理证明的复杂性》提出NP理论，从而获得图灵奖。王浩就读于西南联合大学和清华大学，他跟杨振宁同屋，后在哈佛大学完成博士学业。当时也有回到大陆的想法，但是有所徘徊，，但是后续收到身在大陆的父亲的来信，信中痛斥其没有家国情怀等，让他认为此信一定是其父亲受迫所写，便留在美国发展。



阿兰\*罗宾逊发现归结原理，在此之前数学定理证明需要使用大量规则，而有了归结原理，所有的定理证明可以直接归结到一条规则上。根据希尔伯特形式主义的观点，证明就是把一串公式重写成另外一串公式。从某种意义上说项重写就是拉姆达演算。也许数学形式或者严谨表述会比较复杂，但是这个对于程序员来讲不算新鲜事物。现代编程语言中都有lambda表达式背后的数学原理就在此。



在数学定理证明这块，除了王浩做出极为突出的贡献另外一个重要贡献的团队就是阿贡实验室的数学定理证明小组。二战期间费米在芝加哥大学做出来第一个核反应堆。后面以此构建了阿公国家实验室，里面有一个部门负责应用数学与科学计算，而数学定理证明小组就在这个部门。该小组在那个时代，引领整个数学机器定理证明的发展。该小组的马库恩，用C写了定理证明器Otter，实现了当时定理证明领域的所有先进技术。



大多数定理证明器使用反证法，就是把定理的反证法表述输入程序，然后得到矛盾，进而验证定理是否正确。哥德尔证明了一阶整数(算术)是不可判定的，但是几乎在同时，塔尔斯基则证明一阶实数(初等几何和代数)是可以判定的。基于此可以认为存在算法对所有初等几何和代数问题给出证明。塔尔斯基给出的算法是超指数级别时间复杂度的。即使多次改进仍然难以作为通用算法。吴文俊在研究中国数学史中得到启发，针对一大类初等几何问题给出高效算法。在美国的王浩得知吴文俊的成果后，立刻给吴文俊写信，建议他利用已有的代数包甚至自己动手写程序实现吴方法。目前基于逻辑的定理证明器最适合解决代数问题，而几何定理证明器却又是基于代数的。王浩是逻辑系定理证明器的先驱，而吴文俊则开几何定理证明的风气之先。吴文俊在60岁开始学习高级编程语言。在这个高龄有如此行动力，让其在之后的生涯中还出了不少成果。



迈阿密大学每年都举办机器定理证明大赛。\<https://tptp.org/CASC/   基准测试数据集>这个网站包含大量数学定理证明基准测试。在2000年以前，定理证明大赛基本都是Otter获胜，2005年以后曼切斯特大学的“吸血鬼”证明器后来居上。这是这个项目的代码地址\<https://github.com/vprover/vampire  吸血鬼定理证明器>。项目主体使用c++实现，并在内部实现了自己的脚本语言。\<https://hol-theorem-prover.org/    定理证明器>交互式定理证明器。



Otter和吸血鬼从流派上属于逻辑主义。而形式主义的巅峰是boyer-moore定理证明器。这个证明器虽然在人群中名气不大，但是他们在做这个证明器的时候发明的Boyer-moore字符串匹配算法却非常实用，仍是目前最快的字符串匹配算法。在几乎所有的软件包和编程语言中都有实现。



计算机代数学的早期研究者都出自明斯基门下。最有名的程序是MACSYMA，Mathmatica的作者Wolfram也是其用户。还有另外一种定理证明器主要用来做验证器。AUTOMATH 就是早期比较出名的，有人把《分析基础》整本书翻译成了其形式语言。形式化证明的长度是原书的十倍。



定理证明的过程，都是一个规约的过程，无论逻辑派把数学问题规约到更基本的逻辑问题，还是形式派用一套规则不断地变换给定的公式显性形式出现。1976年阿佩尔和黑肯借助计算机辅助证明了四色定理。传统数学家的工作方式是一个数学家推导证明了一个定理，然后其他数学家根据他的论文再推导一次。进行验证。但是这种方式受到了数学定理证明器的冲击。因为使用数学定理证明器进行数学机械化推导，所产生的过程非常长，比如布尔-勾股数问题的证明有200T的数据。如果使用原始的数学家手动推导的行为一个数学家一辈子都看不完。那么这种证明的验证方法就是用另外一个数学家信任的程序去验证一遍。比如使用Mathmatica。由此所产生的行为是对传统数学家的行为的一种颠覆。在一些实验科学，比如物理，生物，验证一个科学结论或者论文的成本身份高昂。比如想验证一个基础物理定律可能要发射专门的科学卫星，要投入几十亿的研发经费。而随着数学机械化的发展，数学也从纯脑力思考变成了依赖设备的学科。不论是唯心或者唯理的数学还是唯物或者经验的实验科学，最终都成了共同式的实用主义。



阿贡实验室的定理证明小组2006年被裁。马库恩失业，后面去了新墨西哥大学任教。matlab就是起源于新墨西哥大学的教授Cleve Moler。吸血鬼证明器现在还在维护更新，我在前面写了代码链接。美国是一个非常现实的国家，即使你的科研成果很突出，但是如果被验证方法没前途，照样后面不会养你。颜宁在美国已经拿了美国科学院的院士，按理来说可以混日子的。但是随着AlphaFold的横空出世，颜宁那种方法就被代替了，在美国就很难拿到资助。所以跑回中国，还从政府那里拿了很多钱。



归根到底，一个人也好，一个团体也好，想要发展的好，就要能引领时代发展。要形成这种能力。我在中国大大小小的科研院所大学科技公司看到的往往是抄袭。他们从来不关心也不培养这种从0到1的能力，而是听到别人搞出来了，想方设法去模仿抄袭。新一代人里面的确出现了一些不愿意干这种事情，要去自己做一些探索，甚至去引领发展的。但是比例很低很低。



这个链接可以查看google词条的信息。看那些词条在在各个年代的检索数量与比例关系。\<https://books.google.com/ngrams/  谷歌词条引擎>



数学定理证明器领域的最高奖是埃尔布朗奖。

* [Aart Middeldorp](http://cl-informatik.uibk.ac.at/users/ami/) (2025)
* [Armin Biere](https://cca.informatik.uni-freiburg.de/biere/) (2024)
* [Moshe Vardi](https://www.cs.rice.edu/~vardi/) (2023)
* [Natarajan Shankar](https://www.csl.sri.com/people/shankar/) (2022)
* [Tobias Nipkow](https://www21.in.tum.de/~nipkow/) (2021)
* [Franz Baader](https://tu-dresden.de/ing/informatik/thi/lat/die-professur/franz-baader) (2020)
* [Nikolaj Bjørner](https://www.microsoft.com/en-us/research/people/nbjorner/) and [Leonardo de Moura](https://www.microsoft.com/en-us/research/people/leonardo/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Fleonardo%2Fz3_doc%2Fgroup__z3native.html) (2019)
* [Bruno Buchberger](https://www.risc.jku.at/people/buchberger/) (2018)
* [Lawrence C. Paulson](https://www.cl.cam.ac.uk/~lp15/) (2017)
* [Zohar Manna](https://theory.stanford.edu/~zm/) and [Richard Waldinger](https://www.ai.sri.com/~waldinge/) (2016)
* [Andrei Voronkov](https://voronkov.com/) (2015)
* [Robert L. Constable](https://www.cs.cornell.edu/home/rc/) (2014)
* Greg Nelson (2013)
* [Melvin Fitting](https://comet.lehman.cuny.edu/fitting/) (2012)
* [Nachum Dershowitz](https://www.cs.tau.ac.il/~nachum/nachumd/Homepage.html) (2011)
* [David Plaisted](https://www.cs.unc.edu/~plaisted/) (2010)
* [Deepak Kapur](https://www.cs.unm.edu/~kapur/) (2009)
* [Edmund Clarke](https://www.cs.cmu.edu/~emc/) (2008)
* [Alan Bundy](https://homepages.inf.ed.ac.uk/bundy/) (2007)
* [Wolfgang Bibel](https://www.intellektik.de/index/WolfgangBibel.htm) (2006)
* [Martin Davis](https://www.cs.nyu.edu/cs/faculty/davism/) (2005)
* [Harald Ganzinger](https://www.mpi-sb.mpg.de/~hg/) (2004)
* [Peter B. Andrews](https://gtps.math.cmu.edu/andrews.html) (2003)
* [Mark E. Stickel](https://www.ai.sri.com/~stickel/) (2002)
* [Donald Loveland](https://www.cs.duke.edu/~dwl/) (2001)
* [William W. McCune](https://www-unix.mcs.anl.gov/~mccune/) (2000)
* [Robert S. Boyer](https://www.cs.utexas.edu/users/boyer/) and [J Strother Moore](https://www.cs.utexas.edu/users/moore/) (1999)
* [Gérard Huet](https://pauillac.inria.fr/~huet/) (1998)
* [Wen-Tsun Wu](https://www.mmrc.iss.ac.cn/~wtwu/) (1997)
* J. Alan Robinson (1996)
* Woody Bledsoe (1994)
* [Larry Wos](https://www-unix.mcs.anl.gov/~wos/) (1992)


以上是历届得主。



书籍推荐

Handbook of Automated Reasoning



定理证明在2023大模型横空出世后，又出现了新的发展方向。由于当前大模型都是以NLP为基础，那么将数学定理当成一种语言与学习预测，就成为一种新的定理证明方法。当然现阶段的大模型还在学习中学竞赛等模式比较固定的习题，在纯数学的定理证明上还有极大地改善空间。



我认为，数学作为人类最高级的智慧形式，是衡量AI能力强弱的最关键指标。第一波由深度学习引发的AI浪潮更多的是训练AI模型做一些人类能做的非常基础简单的事情，比如目标识别，像素分割，语音识别。对于人类高级能力是严重缺乏的。而以大模型为代表的AI2.0时代，大模型已经可以轻松突破图灵测试，人类越来越难以判断一个行为到底是人做的还是AI做的。为了培育未来的超级智能体，突破人类的局限性，提升AI在人类高级行为的能力，是重要的研究方向，也将彻底改变世界。而AI在数学能力的提升，后续会进一步推广到科学与工程中，这将进一步改变人类知识科技的发展进化速度。引爆因一轮科技革命。



数学形式化标准测试集

https://github.com/openai/miniF2F

https://github.com/hendrycks/math

https://math-qa.github.io/

https://paperswithcode.com/datasets?task=mathematical-reasoning



# 3.从专家系统到知识图谱

费根鲍姆---专家系统之父，图灵奖获得者。

李德伯格---诺贝尔生理学奖得主，开创斯坦福大学医学院



李德伯格在斯坦福医学院接了探索太空生命的课题，也就是用质谱仪分析火星探测的数据。而费根鲍姆擅长机器学习，一个有数据，一个有处理数据的算法，两者一拍即合。另外一个合作者是避孕药的发明者翟若适。他们三个合作，做了DENDRAL，这个系统输入是质谱仪数据，输出是物质的化学式。现在很多人搞大模型，AI FOR SCIENCE，其实在上个世界60年代就已经做出一些AI跟科学的应用了，只不过没用大模型技术而是使用专家系统。当然在那个年代，专家系统的通用性不太好，需要人工去编写规则。MYCIN是布坎南开发的专家系统，是医学诊断领域的。针对细菌感染的诊断系统。当时其处方准确率为69%而专科医生的准确率为80%。专家系统在二十世纪八十年代到九十年代是黄金期，到了九十年代初期开始凋零。在九十年代末期互联网开始兴起，专家系统新瓶装旧酒改名为规则引擎。征信反欺诈风控都使用专家系统。即使到了2025年，征信反欺诈风控可以使用大数据技术获得更真实有效的数据和统计，后端使用的算法也更新成了更先进的数据挖掘算法和AI算法，甚至多模态算法。但是核心的技术体系还是原来那套。只不过实现算法的方式从一条又一条手写的规则变成从大量数据中自动提取特征并根据人为指定的少量目标去自动优化算法。



构建知识图谱，最基础的事情就是要表达知识也即知识表示。一种方法是逻辑，比如律师事务所属于公司属于组织属于事物。这就是逻辑背后就是集合论。另外一种方法是把词语定义出其上下位，比如车辆是摩托的上位，而轮式运载工具是车辆的上位。由这种一层一层的抽象所形成的框架，在编程语言里面成为类型。由此人类设计出了面向对象编程语言。所以AI对整个计算机领域带来各种互相交杂的影响。前面也说了AI早期的符号主义做的数学定理证明器引发出了算法复杂度理论。



只是图谱这块，现在都要跟大数据和AI结合。这块现在还有很大的应用价值。很多企业也有研发岗位。



# 4.第五代计算机的教训

五代机是日本在1982奶奶提出的计划，该计划想摆脱日本只是制造业大国而不是经济科技大国的局面，是一场转型。当时日本所面临的情形非常类似于最近几年的中国，都是内部需要转型，外部面临美国的打压。在编程语言上，日本选择prolog，因为这么语言不是被美国所掌握的，就像现在中国选择linux操作系统risc-v硬件架构，其中也夹杂着一堆民族复兴之类的民族主义情节。在软件上，使用大量的并行计算，提升计算机的计算能力和相关人工智能的能力。最终还是失败了。也许是受限于时代，当初的很多设想在几十年后，被大量使用神经网络的软硬件实现了。日本有时候真的有点悲催。



# 5.神经网络简史

神经网络是麦卡洛克和皮茨在1943年提出来的。那时候刚打完百团大战，还在干扒铁轨炼钢做武器的事情。这两个人出身天壤之别。麦卡洛克是标准美国精英家庭出身，本科耶鲁硕博哥伦比亚大学。他读的医学不太懂数学。皮茨就比较坎坷了，在读中学的时候看到了罗素的《数学原理》，就给罗素写信，经过交流罗素觉得他是可造之材，就邀请他去英国跟自己学习逻辑学，但是他家里穷，连高中都上不起。15岁就被他爸爸要求退学赚钱养家。于是他离家出走。那个时候罗素在美国芝加哥大学任教，他就跑到芝加哥大学找到罗素，罗素把他推荐给卡尔纳普，卡尔纳普想看看他多聪明，就把自己写的书《语言的逻辑句法》给他读。不到一个月他看完了，在原书中写满了笔记交给卡尔纳普。卡尔纳普惊为天人，于是让他在学校打扫卫生。这样至少可以不流浪街头。卡尔纳普是美国著名的分析哲学家。其实AI和哲学逻辑数学都是融为一体发展的，现在很多所谓的AI从业者或者学者，其实大多数其实都是盲流。对AI的本质的认识和思考是缺乏哲学性思考的。皮茨也就是在芝加哥认识了麦卡洛克。这两个人正好互补，就发表了神经网络的开山之作。



1957年罗森布拉特提出感知机，可以用来处理一些简单的视觉任务。当时还是单层感知机。但是明斯基跟他跟不对付，于是写了一本书专门论述感知机的缺陷，现在深度学习很多教材都会说单层感知机不能处理异或，这个结论就出自这本书。因为出了这个事情，对于感知机相关的资助就变少了，罗森布拉特在自己生日那天溺亡了。很多人觉得是不堪受辱。而且明斯基在这本书中就明目张胆地diss他。多年后明斯基把书中针对他的话删了。



感知机不能处理异或问题之后神经网络就陷入低谷期。后面哈佛大学的沃波斯提出多加一层神经网络并且利用后向传播的学习方法解决异或问题。这个已经跟现代的深度神经网络结构非常接近了。 这篇文章虽然对后世影响深远，但是在但是神经网络低谷期没啥人看。真正让神经网络复苏的是霍普菲尔德，他不仅提出新的神经网络结果，还在八十年代计算机算力不够强的时代，自己设计电路用硬件实现了神经网络结构。还培养了一大堆神经网络的新人。也就是他在2024年跟辛顿一起获得了诺贝尔物理学奖。辛顿早年也比较坎坷，倒不是经济上的，因为他是提出布尔代数的布尔的外曾曾孙子，家里是书香门第，只是他研究的神经网络在那个时代不受重视，求职屡屡碰壁，最后润到加拿大。真正打了一场翻身仗是2006年他在科学上发表的论文，提出降维和逐层预训练使得深度学习变成一种实用技术，在深度学习的最后几层，每个节点都对应某些概念。当然在产业界的掀起惊涛骇浪还要等到2012年他带领两个博士生，在计算机视觉挑战赛上以断档式的领先，一鸣惊人。从其先开以深度学习为核心的AI产业革命。**&#x20;**&#x4E24;个学生分别是Ilya Sutskever、Alex Krizhevsky，其中Alex提出Alex网络。Ilya则从谷歌离职后去了openai，并领导开发出chatgpt，掀起AI2.0时代的浪潮。



一个小插曲是这三个人在火爆之后，很多大公司都想得到他们，他们成立一家三人公司，后面被谷歌用几千万美金收购了。其实但是百度更早联系了他们，但是最终他们凭借自己的眼光拒绝了百度。说明他们能做出来如此优秀的成果，眼光也是很好的。如果加入百度不仅职业生涯可能毁了。



# 6.计算机下棋简史：机定胜天，人定胜天

主要是跳棋，国家象棋，中国象棋和围棋。



最开始是跳棋，20世界八十年代开始，阿尔伯塔大学Chinook开始向人类跳棋冠军挑战。而且可以在一些棋局战胜人类。2007年通过数学证明只要对弈双方不犯错，最终都是和棋。跳棋问题终结。算是盖棺定论了。



1959年，麻省理工的几个本科生在麦卡锡的指导下研究计算机下棋，当他们毕业时，他们的程序已经可以击败象棋的初学者了。这是二战刚结束不久，很多地方还在啃树皮。到了六十年代苏联也开发了象棋下棋程序，并且在比赛中击败美国改进的程序。1971年苏联新程序KAISSA和传奇大师斯帕斯基赛了两场，一负一和。震惊世界。到了80年代，出现了两个新一代象棋程序。一个是跑在超级计算机上的Blitz，另外一个是贝尔实验室的Belle。其中Belle的发明人之一就是汤普森，他发明了unix(现代苹果操作系统，波音747飞行系统，安卓手机操作系统都是unix变种)和C语言。1982年这个下棋程序要去苏联参加比赛，却被美国海关没收，原因是企图向苏联输送先进武器。这并不可笑。现在中国也获得了这样的待遇。在三十年前，很多去美国或者发达国家留学的留学生如果选择回国发展，都会在自己的行李箱里面塞很多科技资料或者实验仪器。当时查的不那么严格，所以很多都带回来了。现在如果这么做很大概率会被查出来，甚至被抓。到了八十年代，麻省理工学院的柏林纳开始用硬件技术下棋，就是把软件编程的程序直接用硬件电路实现。他的成果HiTech马上成为最强下棋程序。许峰雄在CMU读计算机体系的博士，他被拉到HiTech项目帮忙设计一个硬件评估函数，但是许跟柏林纳不睦。在资金有限的情况下，许跟其他几个研究生开发出ChipTest，并且很快成为HiTech竞争对手。都是他导师帮忙才能化险为夷。ChipTest的改进版“深思”成为世界上第一个国际象棋特级大师的机器棋手。IBM认识到它的价值把整个团队挖了过去，把对手选定为世界冠军俄罗斯特级大师斯帕罗夫。并改名为深蓝。第一年机深蓝输了，第二年再战，机器赢了。虽然这个程序赢了人类，但是很多人认为这并不是智能。在击败人类后，深蓝团队被裁撤。十几年后，2006年中国象棋被机器攻破，就剩下难度最大的围棋了。



围棋因为组合可能性多，画出博弈树的所有树枝后，在上面跑阿尔法贝塔剪枝不太经济。于是开始改用蒙特卡洛方法。2016年，deepmind的alphaGo使用强化学习击败李世石，正式开启AI1.0产业革命。几个月后，我选择从中科院申请退学，退出天文航天领域，开始全身心投入到AI行业。因为我认为空间的探索，不能仅仅依赖国家拨款的科研，而应该首先通过AI引发产业变革，大幅提高生产力，并改变当前全球的生产关系及意识形态，构建全新的社会体系，将人类从出生到成熟几十年的学习过程全部信息化并培育AI，并用AI去加快科技迭代速度，突破基础科学局限，再去探索空间。否则生产力水平太低，根本无法支撑大规模空间探索。也没有办法设计制造完全跟当前化学火箭原理完全不同的新型空间运载器。



强化学习的发明者巴托和萨顿，后面也获得了图灵奖。冯诺依曼在普林斯顿的主要助手是博克斯，博克斯培育了霍兰德，他提出了遗传算法，他有一个学生科德，发明了关系型数据库而获得图灵奖。而巴托是霍兰德的另外一个学生。



# 7.自然语言处理

自然语言处理起于1953年，IBM资助乔治敦大学进行了有史以来第一次机器翻译，这比达特茅斯会议还要早。但是整体效果不好，美国相关科研资助机构也大幅削减相关资助预算。首先做出突破的是乔姆斯基。乔姆斯基3型文法(正则表达式)等价于优先自动机。2型文法(上下文无关文法)等价于下压自动机。1型文法(上下文相关文法)等价于线性有界非确定图灵机，0型文法等价于图灵机。桥哈姆司机除了搞学术，还是公共知识分子。他是犹太人，但是同情崩了斯坦，而被以色列禁止入境，他拿军方的钱搞科研，但是他反建制。1955年他收到证明通知，但是按照他的性格肯定不愿意为美利坚军队效力，可他在哈佛的成果不足以拿到哈佛的不是，所以他走后门跑到宾夕法尼亚大学，随便走个流程就拿到博士学位。这叫做大佬提携。从他最终的成就和对人类做出的贡献来看，给他几个博士学位都不为过的。这就是欧美大学存在的自由度。国内为了方式腐败，都会尽力去做到公平。但是很多时候一个人到底什么价值没有办法量化，最后结果就是僵化的应试。公立大学拿民众的税款，追求公平是没问题的，但是私立大学，是应该提供这种灵活度的。至于有了这种灵活度，大学是做成世界顶尖大学还是成为纯卖文凭的地方，就看大学自己的水平与操守了。本质上为一些天赋型选手开一些绿灯让其不被繁文缛节所耽误，是一个优秀的大学应该提供的。后来乔姆斯基出了名，可是他的观点很多都反主流，导致他一直被很多人仇恨甚至要刺杀他，麻省理工也知道他的贡献，为了保护这个院宝，还给他专门配了保镖。



真正第一个聊天机器人是魏森鲍姆做出来的，叫做ELIZA。到了60年代，斯坦福大学开始突飞猛进，一大堆天才加盟，比如麦肯锡、费根鲍姆、李德伯格，翟若适。还有科尔比，他做了一个计算机聊天程序PARRY。1972年世界计算机通信年会，通过互联网前身的ARPANET，位于波士顿的ELIZA和位于斯坦福的PARRY进行了聊天，两个都是机器人程序。



2025年什么最火爆，是AI。AI领域什么最火爆，是具身智能和大模型。具身智能机器人核心就是能根据视觉看到的环境，做一些动作，比如抓取，或者根据与人交谈，做一些动作。那么这个起源来自哪里呢？



1967年维诺格拉德来到MIT，当时他的来时是明斯基。他用显示器做了一个虚拟积木世界SHRDLU。为每个积木设置属性。人可以通过自然语言，命令对积木世界虚拟操作。当时彩色显示器很少，他用黑白显示器。现代的机器人抓取只是加了显示的机电组件。这个程序除了自然语言处理，还有知识表达，规划。甚至是计算机图形学最早的应用。不过他后来干一行恨一行，后面就不做AI反而批评AI，转行去做人机交互去了。他有两个学生，布林和佩奇，他们俩创建了谷歌。



到了八十年代才是NLP崛起的时代，因为开始使用统计算法。1988年 IBM发表统计机器翻译论文。两年后他们在《计算语言学》发表了更加理论化的论述。这个论文的作者中就有贾里尼克。他是那个时代NLP划时代的人物。另外一个成员是柯克，因为RISC架构在1987年获得图灵奖。机器翻译经历统计机器学习算法后，已经取得很好的实用性，后面又出现神经网络，进一步提高了翻译性能和质量。2023年以后，又出现了新的变化就是基于transform架构的大模型，翻译的准确度又大幅提升甚至超越了绝大多数人类。



# 8.向自然学习：从遗传算法到强化学习

从生物学里面寻找计算模型，两个脉络，一个是麦卡洛克和皮茨的神经网络，演化到现在是神经网络。一个是冯诺依曼的细胞自动机，经历遗传算法、遗传编程，其中一条线演化为强化学习。



遗传算法模拟种群进化过程，首先随机生成初始种群，然后执行主循环。主循环过程是执行策略，从种群中挑选精英为父母，选出精英父母配对，以极小概率变异，将子代个体添加到新种群。主循环每循环一次，就检测停止标准，比如迭代次数或者适用度。



巴托在霍兰德手下读的博士后，被阿比卜招到麻省理工计算机系。在八十年代神经网络经历低谷，所以巴托在MIT把实验室改名为可适应系统，看起来更像接近控制论的方向。巴托在MIT第一个·博士生就是萨顿。在2024年这对师徒共同获得了图灵奖。强化学习的一个基础理论是马尔科夫决策过程，另一个是动态规划。早期的强化学习研究受制于算力限制，主要在游戏领域应用。巴托的实验室在AI不景气的年代收留了一大堆学术浪人，，就有吴恩达的老师乔丹，吴恩达也是靠使用强化学习控制无人机一举成名的。deepmind的很多核心技术人员 ，都是其徒子徒孙。后来萨顿去了加拿大的阿尔伯塔大学，从此阿尔伯塔大学就成为了强化学习的重镇。这就是实力，要有能力吸引合作者在你所在的城市为了你单独开一家公司。萨顿之于强化学习，就像辛顿之于深度学习，LeCun之于卷积神经网络。



无论是遗传算法、强化学习、深度学习，他们都是模仿自然，缺乏计算理论基础。他们不需要解释甚至不需要了解内部原理，只要看输出就够了。这也是当前的现状。



目前最火爆的自动驾驶端到端，具身智能机器人，大模型全部都是它们的影子。

# 9.哲学家与人工智能

哲学在整个人工智能从诞生到几次转折发展，关联度非常大。每一次人工智能方法的起伏背后都有深刻的哲学思想。哲学家分为两类，一类是深刻的，一类是混饭的。没有罗素，就不会有数理逻辑。就不会有哥德尔、丘齐、图灵，也就不会有计算机科学。明斯基提出的框架概念最后衍生成功面向对象程序设计。



塞尔的中文屋和普特南的缸中脑，都是在哲学层面去讨论到底什么是智能。即使是2025年，关于人工智能的这方面讨论依然存在。当前的大模型到底算不算人工智能？它真的有意识吗？



哲学这个学科，从二战开始，就逐步的分离出一些很硬核的方向，比如逻辑学家都在数学系和计算机系，导致哲学的相关人员空洞化，进而造成这个学科空洞化。非逻辑学出身的哲学家除了讲一些晦涩难懂的词语，压根没有接触过什么硬核复杂的问题。我在早年在图书馆看书的时候就发现有这个问题，大量现代的哲学书籍及其作者，严重缺乏数学科学素养，却在那个位置上，导致产出的东西，往往空洞无用。尤其一些马哲之类的，好像除了背诵固定的书本内容，从来不知道变通。

也许带动哲学真正发展的并不是拥有教职身份的哲学家。真正的哲学绝对不是空洞的一些符号堆叠，而是能从抽象具体到实际事物的基本原理。



# 10.人是机器吗？---人工智能的计算理论基础

计算理论中P问题是可以在多项式时间内求解的问题，而NP问题是可以在多项式时间验证，但是不能保证可以在多项式时间内求解的问题。P到底等于不等于NP目前没有确定。如果所有NP问题都可以以多项式时间规约到某个问题，则该问题成为NP Hard问题。NP Hard问题未必可以在多项式时间内验证问题。所有NP问题都可以在多项式时间被规约成NPC问题。所以如果任何NPC问题可以在多项式时间内得到解决，则该解法可应用到所有NP问题上。



图灵机的基本模型是一个纸带，按照顺序里面存着一系列格子。每个格子里面存储0或者1。一个读写头可以读取或者写入0和1。读写头连接一个有限状态机，会根据读取的数据和位置等条件进行状态转换。图灵在普林斯顿读的博士，是丘齐的学生，图灵证明了图灵机等价于丘齐拉姆达演算。而拉姆达演算又被证明和递归函数等价。丘齐的博士生不仅有图灵，还有一大堆数学家和图灵奖得主，比如拉宾、斯科特、戴维斯等。图灵和丘齐等人证明当时的各种计算装置(递归函数、post系统、拉姆达演算、图灵机)都是可以互相模拟的。图灵-丘齐论题不能被数学严格证明，这是一种观察的经验总结。根据这个结论，可以用图灵机模拟任何程序，这时就虚拟机的基本原理。有了图灵机，就可以把逻辑和数学等跟物理世界联系起来，图灵机的实现就是基于物理的计算机。



# 11.智能的进化

生物学家乌泽尔用实验方法测定，人类大脑大约有860亿个神经元，大脑皮层的神经元数量决定了智力的水平。作为对比，大象脑中又2570亿个神经元，但是绝大多数都位于小脑中，在大脑皮层的神经元数量仅为56亿。所以大象的智能水平低于人类。以前的机器只是可以节省人的体力，但是现在的智能机器，是可以比人传宗接代更高的效率进行进化。图灵关于论可计算数的文章中，证明了图灵机和其他计算装置的等价性，而图灵丘齐论断，说明任何计算装置都等价于图灵机。这就意味着图灵机可以通往强人工智能。



# 12.当我们谈论生死时，我们在谈论什么？

智能生命和心灵是什么关系呢？如果一个人的肉身死了，但是智能还保留着，是否意味心灵仍在，生命未死？

任何一项技术或者学问，最终的归宿都是哲学。那就要去思考生死，前往何处，要去哪里，为什么？



# 13.总结与分析

人工智能从上世纪四五十年代起步，经历了多次高潮和低谷。其背后的指导思想，算法、硬件也经历了多次的更新换代。2025年，从年初deepseek掀起轻量化大模型和人形机器人的一些展示demo，到年中，ai for coding、Agent再到端到端、多模态、ai for science，ai for math。AI正在以极快的迭代速度开始从生活的方方面面影响人们。十年前，由深度学习引爆的AI1.0时代，计算机视觉无疑是做火爆的，而彼时NLP远没有现在这么风光无量。当时去做识别分割等对于人类简单地重复工作，配合互联网、机器人等信息或者终端执行器，已经算是产业革命了。从此开始，大量无人工厂开始出现。智能驾驶开始标配到每一辆新车，自动驾驶开始在很多城市运营。在AI1.0时代，AI更多是取代简单重复的人类工作。2016年阿尔法狗击败李世石，我认识的很多学长从大厂跑到我都叫不上名字的创业公司，现在这些都是AI独角兽了。商汤，魔门塔等等。几个月后，在经过考虑，我决定离开原来的专业，离开原来的环境，申请了退学，变更自己的职业发展方向，开始进入软件和AI领域。几乎是没有任何经验，没有任何技术，没有任何人脉关系。从0开始，以学徒的心态，做最基础的事情，去获得从优秀创业公司，优秀人才身上获得如何学习，如何做项目，如何做技术的商业化落地。在AI1.0产业化开始的时候，我是一个除了年轻没有任何亮点的小白。



从一开始在北京居无定所，后半夜委身于麦当劳与乞丐为伴。当时他们聚在一起吹牛聊天，而我显得格格不入，看书包里唯一一本书c++。迫于生计，暂时委身一家中关村创业大街上AI创业公司，但是不到一周我就看出来绝对发展不起来，转头就跑路。由于没有收入，我在断伙前的几个小时突然灵光乍现，加了一个北京家教的群，因为是过年期间，北京除了本地人基本是空城，来北京上学的外地大学生都回家了，导致家教工作异常好找。我去了望京soho旁边的一个高档小区给主人看孩子。他们家的男的是互联网创业的老兵，早就财富自由，所以很看重两个孩子教育，我每天上午下午和晚上都去他家，中间回家休息，照顾他家两个孩子，一个马上上初中，一个小学一年级。但是我带他们教给他们的东西，确实知识范围很广的。我要带那个年龄大的读比较深刻的世界名著，我还会根据我看的很多书获得的感悟以及一些生活经验，给她做剖析，因为既有深度又很有乐趣不像学校老师照本宣科，她很喜欢我给她讲课。我在她家的家教地位也就稳了。那个小孩，我给他讲古生物学天文学的科普知识，他没见过世面，也是一下子被我吸引。天天都想跟我一起学习。每天的工资都是当天解算，所以我才挺过最开始财务艰难的阶段。



后面假期结束，虽然平时也要去辅导功课，不过时间少了，赚的也少了。我开始投递简历找AI相关的工作。但是绝大多数的互联网大厂都以我退学和没有实习经验为由拒绝我。当时找了两家公司，其中一家很一般的外包，给接近2万的薪水，但是没什么发展前景。另外一家公司是当前机器人视觉的独角兽，当时只有三十多人。我不是依靠技术能力应聘进去的，因为我从来没有搞过机器人，更不会AI相关的算法，编程都非常差劲。只不过我在面试的时候，因为最近的面试实在太难而崩溃哭了。公司的创始人觉得我可怜才给我一个工作机会，而且只是3个月的签约。如果到时候仍然不满足他们的能力要求就不会有正式的合同。因为是清华的创业团队，团队的人的能力和技术的确让我眼前一亮。只不过自己的专业能力过于差劲，只能做非常基础的拧螺丝。在公司里面不会有人给你专门的学习时间。甚至很多同事都不会教你甚至会给你挖坑。我在里面非常煎熬，我只能依靠态度，获取别人的尊重，用别人不愿意干的脏活累活，获得存在感。但是我也清楚，没有核心技术，强大的实力，是不能在社会上真正有所发展的。于是我结合在中科院读研期间学习的科研方法，白天在公司搬砖，顺便看核心技术人员如何做事情，晚上回家学习基础理论知识，平时对技术大佬殷勤，换取他们一些技术指导。就这样，先从操作做起，一步步编程调试开发算法设计才积累起来。等到我离开再找新的工作，就没那么难了，之前连面试都不给的公司，只要投递简历，面试就给安排。但是技术面试却经常挂掉，原因是他们考察代码的方法是随机选几个leetcode题目让我做，但是我从来不刷，导致很容易面崩。而且经过我研究发现，所谓程序员的这套刷题刷面经的方法，虽然可以在当时能找到一个不错的互联网大厂工作，可是会耗费很多的时间。将时间用去刷题不如去学习更先进的系统和算法论文知识。



所以我做了一个当时旁人认为愚蠢的决定就是绝对不刷题。好处是可以投入充足的时间完善自己。确地就是面试容易笔试跪掉。在那个互联网应届生年年倒挂上一届老学长的年代，这么做事情是很不讨好的。但是我应该坚守本心，去做一些更有价值的事情，而不是随波逐流，被一些落后的思想做法所左右。就在那段时间很多北京土著在北大读研的学生都想退学去搞量化，因为那个时间点房地产是最后的狂欢。互联网一片欣欣向荣。我耐心劝他们不要乱来，如此高昂的放假，互联网企业如此盲目的扩张都会因为人口不再增长，收入不再增长而受到制裁。所谓的繁荣其实是庄家跑路前的炒作。



果不其然两年后，22年年末疫情解封。没有经济触底反弹，反而是大量企业开始裁之前盲目扩招的应届研究生。互联网公司一片一片地砍业务。大量的AI公司开始因为商业化困难亏空太大而破产。我等待的现实终于报复到了这群曾经目空一切的人身上。而等到2023年初，随着chatgpt横空出世，AI2.0时代到来，曾经的刷题小将自以为是地勤奋，终究是抵挡不住2025 ai for coding的强大AI。编程是结构化最好的AI垂直应用领域，代码高度结构化且高度信息化，且信息产业发展这么多你年，开源软件积累了大量高质量数据集，使得从23年到25年彻底，智能编程相关的工具疯狂迭代进化。



截止到2025年，作为一个工程师，我强制要求我写的代码，至少百分之90以上都是AI生成的。我认为我眼光是独到的，但是就现实而言，我看到仍然有大量所谓的科技公司还在用那些AI可以轻易做到的八股文题库去筛选候选人。甚至以此为荣。我相信用不了多久，他们一定会被经济规律所制裁，其研发所产生的高额成本是没有办法卖出去自己产品的。



在2023年开始，我也开始了自己在AI领域的尝试。我在尝试用AI去做工程项目，做科研，做数学公示推导。虽然到现在为止，我并没有做出震惊世界的产品，甚至很多技术尝试都还很失败，但是我相信一个真正的强人工智能，绝对不是现在这样如此庞大的模型和电力消耗。



曾几何时计算机只是科学家的工具，第一个计算机体积跟一座大楼一样高。那是任何普通人都无法企及使用的。而且早期所使用的电子管可靠性也差，仅仅半个世界，计算机随处可见，就在我们的胳膊上。曾几何时，计算机专业的学生要在一台大型机上分为多个用户上机编程，现在随便一个普通的笔记本装上IDE就可以写代码。



智能做需要的能量绝对不是目前这么庞大，智能学习所需要的数据量也绝对不是目前这么庞大。毕竟我做自动驾驶仅仅是想要一个合格的机器司机就可以了，不需要它懂天文地理。



这需要从底层物理原理到基础物理器件再到软件算法全方位的创新。绝对不是对网络规模的无限制扩张。我不敢保证这一定可以在AI2.0时代做到，但是即使如此，当前的AI发展也已经对全球的社会产生极为深刻的影响。这是整个人类社会都没有遇到过的。商业或者社会都会产生极为血腥的淘汰。大量的过往经验都会统统失效。但也会产生巨大的机会。真正做出一番事业的机会。而我相信，这正好适合现在的我！一个就像个人PC普及的AI PC时代在未来二三十年一定会产生。而这就是我去追赶我年少时那些硅谷偶像的机会。

我曾经羡慕一些年代的人，比如十九二十世纪相交年代的欧洲数学物理，他们创造引领了科技革命，让当今的教科书到处都是他们的名字。我也羡慕二战后的美国，信息革命让那个时代的人，产生了当前信息时代所有的基础理论和工具。也许当下正处于智能的一个黄金时代。庆幸地是自己没有被现代文明所隔绝，去亲历，去创造，去改变。
